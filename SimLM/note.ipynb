{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练顺序：\n",
    "# 1、train_nq_binencoder.sh 训练完后，encode 文章，预测训练集，用于生成hard negative\n",
    "# 2、train_nq_rereaker.sh 训练个reranker，用于知识蒸馏。\n",
    "# 3、nq_gen_kd_teacher_scores.sh 得到老师模型的分数，用于后续步骤。\n",
    "# 4、train_nq_kd.sh 训练知识蒸馏后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理数据文件pasage_w100\n",
    "import json\n",
    "with open('/home/shishijie/workspace/project/DPR/downloads/wiki/downloads/data/wikipedia_split/psgs_w100.tsv','r') as fr:\n",
    "    with open('/home/shishijie/workspace/project/unilm/simlm/data/dpr/passages.jsonl','w') as fw:\n",
    "        for line in fr.readlines():\n",
    "            line=line.strip().split('\\t')\n",
    "            fw.write(json.dumps({\n",
    "                'id': line[0],\n",
    "                'contents': line[1],\n",
    "                'title': '-'\n",
    "            })+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nq_train nq_dev 转为jsonl\n",
    "def write_jsonl(filename):\n",
    "    with open(f'./data/dpr/{filename}.json', 'r') as fr:\n",
    "        data=json.loads(fr.read())\n",
    "\n",
    "    with open(f'./data/dpr/{filename}.jsonl', 'w') as fw:\n",
    "        for item in data:\n",
    "            \n",
    "            fw.write(json.dumps(item) + '\\n')\n",
    "\n",
    "write_jsonl('nq-train')\n",
    "# write_jsonl('nq-dev')\n",
    "# write_jsonl('nq-adv-hn-train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def trans(filename, type):\n",
    "    if type == 'json2jsonl':\n",
    "        \n",
    "        # query2id\n",
    "        data_dic={}\n",
    "        with open(f'/home/shishijie/workspace/project/DPR/downloads/wiki/downloads/data/retriever/qas/{filename}.csv', 'r') as fr:\n",
    "            for idx, line in enumerate(fr.readlines()):\n",
    "                line = line.strip().split('\\t')\n",
    "                data_dic[line[0]] = idx\n",
    "        \n",
    "        # 读取带有正负样本的训练集\n",
    "        with open(f'./data/dpr/{filename}.json', 'r') as fr:\n",
    "            data_json=json.loads(fr.read())\n",
    "            \n",
    "        with open(f'./data/dpr/{filename}.jsonl', 'w') as fw:\n",
    "            for item in data_json:\n",
    "                query = item['question']\n",
    "                query_id = data_dic[query]\n",
    "                positives = {'doc_id': [], 'score': []}\n",
    "                positive_ctxs = item['positive_ctxs']\n",
    "                for positive_ctx in positive_ctxs:\n",
    "                    positives['doc_id'].append(positive_ctx['passage_id'])\n",
    "                    positives['score'].append(positive_ctx['score'])\n",
    "                \n",
    "                negatives = {'doc_id': [], 'score': []}\n",
    "                negative_ctxs = item['negative_ctxs']\n",
    "                for negative_ctx in negative_ctxs:\n",
    "                    negatives['doc_id'].append(negative_ctx['passage_id'])\n",
    "                    negatives['score'].append(negative_ctx['score'])\n",
    "                \n",
    "                fw.write(json.dumps({\n",
    "                    'query_id': query_id,\n",
    "                    'query': query,\n",
    "                    'positives': positives,\n",
    "                    'negatives': negatives\n",
    "                }) + '\\n')\n",
    "                \n",
    "    elif type == 'query2tsv':  \n",
    "        with open(f'/home/shishijie/workspace/project/DPR/downloads/wiki/downloads/data/retriever/qas/{filename}.csv', 'r') as fr:\n",
    "            filename = filename.replace('-', '_')  \n",
    "            with open(f'./data/dpr/{filename}_queries.tsv', 'w') as fw:\n",
    "                for line in fr.readlines():\n",
    "                    fw.write(line)\n",
    "    \n",
    "    # 挖掘困难负样本       \n",
    "    elif type == 'minedhn':\n",
    "        data_dic={}\n",
    "        with open(f'/home/shishijie/workspace/project/DPR/downloads/wiki/downloads/data/retriever/qas/{filename}.csv', 'r') as fr:\n",
    "            for idx, line in enumerate(fr.readlines()):\n",
    "                line = line.strip().split('\\t')\n",
    "                data_dic[line[0]] = str(idx)\n",
    "        \n",
    "        with open(f'./data/dpr/{filename}.json', 'r') as fr:\n",
    "            data_json=json.loads(fr.read())\n",
    "        \n",
    "        with open(f'/home/shishijie/workspace/project/unilm/simlm/checkpoint/nq_rerank_2023-12-18-2154.01/checkpoint-20000/nq_train.dpr.json', 'r') as fr:\n",
    "            data_predict = json.loads(fr.read())\n",
    "        \n",
    "        with open(f'./data/dpr/{filename}_distill.jsonl', 'w') as fw:\n",
    "            for item in data_json:\n",
    "                query = item['question']\n",
    "                query_id = data_dic[query]\n",
    "                positives = {'doc_id': [], 'score': []}\n",
    "                positive_ctxs = item['positive_ctxs']\n",
    "                for positive_ctx in positive_ctxs:\n",
    "                    positives['doc_id'].append(positive_ctx['passage_id'])\n",
    "                    positives['score'].append(positive_ctx['score'])\n",
    "                    \n",
    "                negatives = {'doc_id': [], 'score': []}\n",
    "                predict = data_predict[query]\n",
    "                hn_count = 15\n",
    "                for tmp_dic in predict['contexts']:\n",
    "                    if not tmp_dic['has_answer']:\n",
    "                        negatives['doc_id'].append(str(tmp_dic['docid']))\n",
    "                        negatives['score'].append(float(tmp_dic['score']) if tmp_dic['score'] else 0)\n",
    "                        hn_count -= 1\n",
    "                    if not hn_count:\n",
    "                        break\n",
    "                    \n",
    "                negative_ctxs = item['negative_ctxs']\n",
    "                for negative_ctx in negative_ctxs:\n",
    "                    negatives['doc_id'].append(negative_ctx['passage_id'])\n",
    "                    negatives['score'].append(negative_ctx['score'])\n",
    "                \n",
    "                   \n",
    "                fw.write(json.dumps({\n",
    "                    'query_id': query_id,\n",
    "                    'query': query,\n",
    "                    'positives': positives,\n",
    "                    'negatives': negatives\n",
    "                }) + '\\n')\n",
    "                \n",
    "                \n",
    "trans('nq-train', 'minedhn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
